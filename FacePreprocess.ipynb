{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff597fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://github.com/spmallick/learnopencv/raw/master/FaceDetectionComparison/models/opencv_face_detector_uint8.pb\n",
    "!wget https://raw.githubusercontent.com/opencv/opencv_extra/master/testdata/dnn/opencv_face_detector.pbtxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4d09730d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "%matplotlib inline \n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "def detectFaceOpenCVDnn(net, frame):\n",
    "    frameOpencvDnn = frame.copy()\n",
    "    frameHeight = frameOpencvDnn.shape[0]\n",
    "    frameWidth = frameOpencvDnn.shape[1]\n",
    "    blob = cv2.dnn.blobFromImage(frameOpencvDnn, 1.0, (frameHeight, frameWidth), [104, 117, 123], False, False)\n",
    "\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "    bboxes = []\n",
    "    for i in range(detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        if confidence > conf_threshold:\n",
    "            x1 = int(detections[0, 0, i, 3] * frameWidth)\n",
    "            y1 = int(detections[0, 0, i, 4] * frameHeight)\n",
    "            x2 = int(detections[0, 0, i, 5] * frameWidth)\n",
    "            y2 = int(detections[0, 0, i, 6] * frameHeight)\n",
    "            bboxes.append([x1, y1, x2, y2])\n",
    "            if not(x1<30 or y1<30 or x2>frameWidth-30 or y2>frameHeight-30):\n",
    "              y1, y2 = y1-20, y2+20\n",
    "              x1, x2 = x1-20, x2+20\n",
    "            else:\n",
    "              continue\n",
    "            crop_img = frameOpencvDnn[y1:y2, x1:x2]\n",
    "            crop_img = cv2.cvtColor(crop_img, cv2.COLOR_BGR2RGB).astype(\"float32\")\n",
    "            cv2.imwrite(\"cropped\"+str(i)+\".jpg\", crop_img)\n",
    "#             inp = np.array([gan.data_loader.get_img(crop_img)])\n",
    "#             old_img = gan.g_AB.predict([inp])\n",
    "#             new_img = revert_img(old_img[0], (y2-y1, x2-x1))\n",
    "#             new_img = cv2.cvtColor(new_img, cv2.COLOR_RGB2BGR).astype(\"float32\")\n",
    "#             frameOpencvDnn[y1:y2, x1:x2] = new_img\n",
    "#             scipy.misc.imsave(\"old\"+str(i)+\".jpg\", new_img)\n",
    "    return frameOpencvDnn, bboxes\n",
    "  \n",
    "conf_threshold = 0.3\n",
    "modelFile = \"opencv_face_detector_uint8.pb\"\n",
    "configFile = \"opencv_face_detector.pbtxt\"\n",
    "net = cv2.dnn.readNetFromTensorflow(modelFile, configFile)\n",
    "frame = cv2.imread(\"data/trainb/portrait.jpg\")\n",
    "outOpencvDnn, bboxes = detectFaceOpenCVDnn(net,frame)\n",
    "# cv2.imwrite(\"big3_old.jpg\", outOpencvDnn)\n",
    "# outOpencvDnn, bboxes = detectFaceOpenCVDnn(net,frame,1)\n",
    "# cv2.imwrite(\"big3_black.jpg\", outOpencvDnn)\n",
    "# In [0]:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14aa1f8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d8a43b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
